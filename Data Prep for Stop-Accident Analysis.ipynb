{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme\n",
    "\n",
    "The MCPD claim that they allocate officers (and make traffic stops) based on accidents in each area. This file examines the veracity of that claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from shapely.geometry import Point\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\mikha\\Dropbox\\mikhael_misc\\Projects\\Policing Thesis\\New Modified Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"Unique\" Var (but now it's loaded - no need to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique = []\n",
    "# for i in list(range(1,len(df))):\n",
    "#     if df['Stop ID'].iloc[i-1] != df['Stop ID'].iloc[i]:\n",
    "#         unique.append(1)\n",
    "#     else:\n",
    "#         unique.append(0)\n",
    "     \n",
    "# unique = [1] + unique\n",
    "\n",
    "# del df['First Unique']\n",
    "\n",
    "# df.insert(1, 'First Unique', unique)\n",
    "\n",
    "\n",
    "# df.to_csv(r\"C:\\Users\\mikha\\Dropbox\\mikhael_misc\\Projects\\Policing Thesis\\New Modified Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Race set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_set = {'ASIAN', 'BLACK', 'HISPANIC', 'NATIVE AMERICAN', 'OTHER', 'WHITE'}\n",
    "race_set_w_total = {'ASIAN', 'BLACK', 'HISPANIC', 'NATIVE AMERICAN', 'OTHER', 'TOTAL', 'WHITE'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injuries without Accidents\n",
    "\n",
    "Some observations have injuries but no accidents. I remove those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, confirm that they're randomly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.GeoDataFrame(\n",
    "#     df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gdf[(gdf['Accident']==0) & (gdf['Personal Injury']==1) & (gdf['Latitude']!=0) & (gdf['Longitude']<=-75)].plot(figsize=(15,15), markersize=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[~((df['Accident']==0) & (df['Personal Injury']==1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "*coordinates_dict[ longitude_i ][ latitude_j ][ FIELD** ][ race ] = information for that area*\n",
    "\n",
    "** \"field\" equals things like \"Number of Charges @ 9 MPH\", \"Average Speed NOT in 9,14 MPH\", etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up *coordinates_dict*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # cells ~  46427604\n"
     ]
    }
   ],
   "source": [
    "CELL_WIDTH = 0.0001\n",
    "DECIMAL_PLACES = 4\n",
    "\n",
    "MIN_LONGITUDE = -77.6\n",
    "MAX_LONGITUDE = -76.8\n",
    "\n",
    "MIN_LATITUDE = 38.92\n",
    "MAX_LATITUDE = 39.5\n",
    "\n",
    "def rounder(x):#rounds to nearest CELL_WIDTH; X decimal places\n",
    "    return np.around(CELL_WIDTH * round(x/CELL_WIDTH), DECIMAL_PLACES)\n",
    "\n",
    "TOTAL_CELLS = round((((MIN_LONGITUDE-CELL_WIDTH)-(MAX_LONGITUDE+CELL_WIDTH))/CELL_WIDTH)*(((MIN_LATITUDE-CELL_WIDTH)-(MAX_LATITUDE+CELL_WIDTH))/CELL_WIDTH))\n",
    "print('total # cells ~ ', TOTAL_CELLS)\n",
    "\n",
    "coordinates_dict = {}\n",
    "for x in np.arange(MIN_LONGITUDE-CELL_WIDTH, MAX_LONGITUDE+CELL_WIDTH, CELL_WIDTH):\n",
    "    coordinates_dict[rounder(np.around(x,DECIMAL_PLACES))] = {}\n",
    "\n",
    "for x in coordinates_dict:\n",
    "    for y in np.arange(MIN_LATITUDE-CELL_WIDTH, MAX_LATITUDE+CELL_WIDTH, CELL_WIDTH):\n",
    "        coordinates_dict[x][rounder(np.around(y,DECIMAL_PLACES))] = {\n",
    "#                                                 \"All Speeds Over Limit\": {race: [] for race in race_set_w_total},\n",
    "#                                                \"Number of Speeding Charges\":{race: 0 for race in race_set_w_total},\n",
    "#                                                \"Average Speed NOT in 9,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "                                               \n",
    "#                                                  \"Number of Charges @ 9 MPH\": {race: 0 for race in race_set_w_total},\n",
    "#                                                 \"Number of Charges in 9,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "#                                                  \"Number of Charges in 10,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "#                                                 \"Number of Charges NOT in 9,14 MPH\": {race: 0 for race in race_set_w_total}, \n",
    "                                                \n",
    "#                                                  \"Percent of Own Race's Charges @ 9 MPH\": {race: 0 for race in race_set_w_total},\n",
    "#                                                 \"Percent of Own Race's Charges in 9,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "#                                                  \"Percent of Own Race's Charges in 10,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "#                                                 \"Percent of Own Race's Charges NOT in 9,14 MPH\": {race: 0 for race in race_set_w_total}, \n",
    "\n",
    "#                                                 \"Percent of Charges that were CHANGED\": {race: 0 for race in race_set_w_total}, \n",
    "#                                                 \"Percent of Charges that were NOT CHANGED\": {race: 0 for race in race_set_w_total}, \n",
    "                                                                    \n",
    "# #                                                  \"As Percent of All Races' Charges @ 9 MPH\" : {race: 0 for race in race_set_w_total},\n",
    "# #                                                 \"As Percent of All Races' in 9,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "# #                                                  \"As Percent of All Races in 10,14 MPH\": {race: 0 for race in race_set_w_total},\n",
    "# #                                                 \"As Percent of All Races in 9,14 MPH\": {race: 0 for race in race_set_w_total},                                                                      \n",
    "                                                \n",
    "#                                                 \"Number of Citations for Each Stop\": {race: [] for race in race_set_w_total},\n",
    "#                                                 \"Racial Composition\": {race: 0 for race in race_set_w_total},\n",
    "                                                \"Total_Observations\": 0,\n",
    "                                                \"Total_Citations\": 0,\n",
    "                                                \"Total_Accidents\": 0,\n",
    "                                                \"Total_Injuries\": 0,\n",
    "                                                \"Total_Fatalities\": 0,\n",
    "                                                \"Total_Stops\": 0,\n",
    "            \n",
    "                                                \"Total_ASIAN_Stops\": 0,\n",
    "                                                \"Total_BLACK_Stops\": 0,            \n",
    "                                                \"Total_HISPANIC_Stops\": 0,                                                                    \n",
    "                                                \"Total_OTHER_Stops\": 0,\n",
    "                                                \"Total_WHITE_Stops\": 0,\n",
    "            \n",
    "                                                \"Total_Speeds_Altered\": 0,\n",
    "                                                \"Total_Speeds_Not_Altered\": 0\n",
    "        \n",
    "        }\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def Rounding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def rounder(x):\n",
    "    \"\"\"\n",
    "    Rounds to nearest CELL_WIDTH; decimal places\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.around(CELL_WIDTH * round(x/CELL_WIDTH), DECIMAL_PLACES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounder2(x):\n",
    "    \"\"\"\n",
    "    Rounds to nearest CELL_WIDTH; decimal places\n",
    "    \"\"\"\n",
    "    round(x, DECIMAL_PLACES)\n",
    "    \n",
    "    \n",
    "#     return np.around(CELL_WIDTH * round(x/CELL_WIDTH), DECIMAL_PLACES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill *coordinates_dict*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# zipped_vars=list(zip(df['Longitude'], df['Latitude'], df['Race'], df['Speed Over Posted Limit'], df['Number of Citations']))\n",
    "\n",
    "for i,x in enumerate(list(zip(df['Longitude'], df['Latitude'], df['Race'], df['Speed Over Posted Limit'], df['Citation - (D_Violation Type)'], df['Accident'], df['Personal Injury'], df['Fatal'], df['First Unique'], df['Speed Altered']))):\n",
    "        if MIN_LONGITUDE <= x[0] <= MAX_LONGITUDE: #-77.6 <= x <= -76.8\n",
    "            if MIN_LATITUDE <= x[1] <= MAX_LATITUDE:\n",
    "\n",
    "#                 coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Racial Composition\" ][ x[2] ] += 1\n",
    "#                 coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Racial Composition\" ][ 'TOTAL' ] += 1\n",
    "                \n",
    "                coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Observations\" ] += 1\n",
    "                coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Citations\" ] += x[4] \n",
    "                coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Accidents\" ] += x[5] # ==1 if accident\n",
    "                coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Injuries\" ] += x[6]\n",
    "                coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Fatalities\" ] += x[7]\n",
    "                coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Stops\" ] += x[8]\n",
    "                if x[2] == 'ASIAN':\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_ASIAN_Stops\" ] += x[8]\n",
    "                elif x[2] == 'BLACK':\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_BLACK_Stops\" ] += x[8]\n",
    "                if x[2] == 'HISPANIC':\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_HISPANIC_Stops\" ] += x[8]\n",
    "                if x[2] == 'OTHER':\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_OTHER_Stops\" ] += x[8]\n",
    "                if x[2] == 'WHITE':\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_WHITE_Stops\" ] += x[8]\n",
    "                    \n",
    "                if x[9]==1: #if speed altered (and not nan)\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Speeds_Altered\" ] += 1\n",
    "                elif x[9]==0: #if speed NOT altered (and not nan)\n",
    "                    coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Total_Speeds_Not_Altered\" ] += 1\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "#                 if not np.isnan(x[3]): # if df[\"Speed Over Posted Limit\"].iloc[i] != np.nan\n",
    "                    \n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Speeding Charges\" ][ x[2] ] += 1\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Speeding Charges\" ][ 'TOTAL' ] += 1\n",
    "\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"All Speeds Over Limit\" ][ x[2] ].append(x[3])\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"All Speeds Over Limit\" ]['TOTAL'].append(x[3])\n",
    "\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Speeding Charges\" ][ x[2] ] += 1\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Speeding Charges\" ][ 'TOTAL' ] +=1\n",
    "\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Citations for Each Stop\" ][ x[2] ].append(x[4])\n",
    "#                     coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Citations for Each Stop\" ][ 'TOTAL' ].append(x[4])\n",
    "\n",
    "\n",
    "#                     if x[3] == 9:\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges @ 9 MPH\" ][ x[2] ] += 1\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges @ 9 MPH\" ][ 'TOTAL' ] += 1\n",
    "\n",
    "#                     if 9 <= x[3] <= 14:\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges in 9,14 MPH\" ][ x[2] ] += 1\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges in 9,14 MPH\" ][ 'TOTAL' ] += 1\n",
    "\n",
    "#                     if 10 <= x[3] <= 14:\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges in 10,14 MPH\" ][ x[2] ] += 1\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges in 10,14 MPH\" ][ 'TOTAL' ] += 1\n",
    "                        \n",
    "#                     if 9 > x[3] or x[3] > 14:\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges NOT in 9,14 MPH\" ][ x[2] ] += 1\n",
    "#                         coordinates_dict[ rounder(x[0]) ][ rounder(x[1]) ][ \"Number of Charges NOT in 9,14 MPH\" ][ 'TOTAL' ] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pd dataframe from coordinates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dict to pd df\n",
    "allocation_balance_df = pd.DataFrame.from_dict({(i,j): coordinates_dict[i][j] \n",
    "                           for i in coordinates_dict.keys() \n",
    "                           for j in coordinates_dict[i].keys()},\n",
    "                       orient='index')\n",
    "\n",
    "#give names to multi-index\n",
    "allocation_balance_df.index.names = ['long', 'lat']\n",
    "\n",
    "#convert indices to cols\n",
    "allocation_balance_df.reset_index(level=allocation_balance_df.index.names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to geopandas dataframe\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    allocation_balance_df, geometry=gpd.points_from_xy(allocation_balance_df['long'], allocation_balance_df['lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fields\n",
    "gdf['Observations_per_Accident'] = gdf['Total_Observations'] / gdf['Total_Accidents']\n",
    "gdf['Accidents_per_Observation'] = gdf['Total_Accidents'] / gdf['Total_Observations']\n",
    "\n",
    "gdf['Observations per Injury'] = gdf['Total_Observations'] / gdf['Total_Injuries']\n",
    "gdf['Injuries_per_Observation'] = gdf['Total_Injuries'] / gdf['Total_Observations']\n",
    "\n",
    "gdf['Observations per Fatality'] = gdf['Total_Observations'] / gdf['Total_Fatalities']\n",
    "gdf['Fatalities_per_Observation'] = gdf['Total_Fatalities'] / gdf['Total_Observations']\n",
    "\n",
    "gdf['Stops_per_Accident'] = gdf['Total_Stops'] / gdf['Total_Accidents']\n",
    "gdf['Accidents_per_Stop'] = gdf['Total_Accidents'] / gdf['Total_Stops']\n",
    "\n",
    "gdf['Stops_per_Injury'] = gdf['Total_Stops'] / gdf['Total_Injuries']\n",
    "gdf['Injuries_per_Stop'] = gdf['Total_Injuries'] / gdf['Total_Stops']\n",
    "\n",
    "gdf['Citations_per_Stop'] = gdf['Total_Citations'] / gdf['Total_Stops']\n",
    "\n",
    "gdf['pct_Stops_ASIAN'] = gdf['Total_ASIAN_Stops'] / gdf['Total_Stops']\n",
    "gdf['pct_Stops_BLACK'] = gdf['Total_BLACK_Stops'] / gdf['Total_Stops']\n",
    "gdf['pct_Stops_HISPANIC'] = gdf['Total_HISPANIC_Stops'] / gdf['Total_Stops']\n",
    "gdf['pct_Stops_OTHER'] = gdf['Total_OTHER_Stops'] / gdf['Total_Stops']\n",
    "gdf['pct_Stops_WHITE'] = gdf['Total_WHITE_Stops'] / gdf['Total_Stops']\n",
    "\n",
    "gdf['pct_Altered'] = gdf['Total_Speeds_Altered'] / ( gdf['Total_Speeds_Altered'] + gdf['Total_Speeds_Not_Altered'] )\n",
    "\n",
    "\n",
    "#replace inf with 0\n",
    "gdf.replace(np.inf, 0, inplace=True)\n",
    "\n",
    "#drop cells with less than 30 Observations\n",
    "gdf = gdf[gdf['Total_Observations']>=30]\n",
    "\n",
    "# replace nan with zero\n",
    "gdf.fillna(0, inplace=True)\n",
    "\n",
    "# normalize fields\n",
    "for field in list(set(gdf.columns) - set(['long', 'lat', 'geometry'])): #all cols excep long, lat, geometry\n",
    "    gdf['Normalized ' + field] = (gdf[field]-gdf[field].mean())/gdf[field].std()\n",
    "    \n",
    "# replace nan with zero again after normalizing\n",
    "gdf.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to Nearest Police Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_locations = {} #each number corresponds to its district\n",
    "\n",
    "# station_locations[1] = Point([39.058586719462355, -77.04866263431445])\n",
    "# station_locations[2] = Point([38.99134343887121, -77.0978411276706])\n",
    "# station_locations[3] = Point([39.04628489091019, -76.99114687774473])\n",
    "# station_locations[4] = Point([39.05934890838263, -77.04882510089048])\n",
    "# station_locations[5] = Point([39.18443844480189, -77.26277546702069])\n",
    "# station_locations[6] = Point([39.15007606517369, -77.23548162468924])\n",
    "\n",
    "station_locations[1] = Point([-77.04866263431445, 39.058586719462355])\n",
    "station_locations[2] = Point([-77.0978411276706, 38.99134343887121])\n",
    "station_locations[3] = Point([-76.99114687774473, 39.04628489091019])\n",
    "station_locations[4] = Point([-77.04882510089048, 39.05934890838263])\n",
    "station_locations[5] = Point([-77.26277546702069, 39.18443844480189])\n",
    "station_locations[6] = Point([-77.23548162468924, 39.15007606517369])\n",
    "\n",
    "\n",
    "for district in station_locations:\n",
    "#     gdf[f'District_{district}_Station_Location'] = station_locations[district]\n",
    "    \n",
    "    gdf[f'Distance_to_District_{district}_Station'] = gdf.distance(station_locations[district])\n",
    "    \n",
    "\n",
    "distance_fields = [f'Distance_to_District_{district}_Station' for district in station_locations]\n",
    "\n",
    "gdf['Distance_to_Closest_Station'] = gdf[distance_fields].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_fields = [f'Distance_to_District_{district}_Station' for district in station_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['Distance_to_Closest_Station'] = gdf[distance_fields].min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.DataFrame(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "gdf.to_csv(f\"Police Stops vs Accidents - width={str(CELL_WIDTH)} - {today}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geopandas_env]",
   "language": "python",
   "name": "conda-env-geopandas_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
